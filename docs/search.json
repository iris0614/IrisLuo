[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "ABOUT",
    "section": "",
    "text": "üìÉMy Resume"
  },
  {
    "objectID": "about.html#what-i-do",
    "href": "about.html#what-i-do",
    "title": "ABOUT",
    "section": "What I Do",
    "text": "What I Do\nI specialize in:\n\nData Cleaning and Transformation: Ensuring data integrity and preparing datasets for sophisticated analysis by employing best practices in data wrangling.\nData Analysis and Visualization: Leveraging tools like Power BI, Tableau, and Python to turn complex data into clear, actionable insights, improving decision-making processes.\nMachine Learning and AI Development: Applying machine learning models to solve real-world problems, particularly in areas like natural language processing and predictive analytics."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "ABOUT",
    "section": "Education",
    "text": "Education\n\nMaster of Data Science (GPA: 4.23/4.33)\nUniversity of British Columbia (Vancouver, BC)\nSep 2023 ‚Äì Jun 2024\nRelevant Courses: Statistical Inference and Computation, Regression, Spatial and Temporal Models, Supervised Learning, Unsupervised Learning, Data Visualization, Algorithms and Data Structures, Collaborative Software Development, Databases and Data Retrieval, Web and Cloud Computing\nMaster of Science in Economics (GPA: 86.7/100)\nHuazhong University of Science and Technology (Wuhan, China)\nSep 2020 ‚Äì Jun 2023\nPublic Economics (Exchange) (GPA: 3.7/4.0)\nUniversity of California Berkeley (California, United States)\nJul 2021 ‚Äì Aug 2021\nBachelor of Science in Economics (GPA: 88.63/100)\nCentral China Normal University (Wuhan, China)\nSep 2016 ‚Äì Jun 2020"
  },
  {
    "objectID": "about.html#capstone-project",
    "href": "about.html#capstone-project",
    "title": "ABOUT",
    "section": "Capstone Project",
    "text": "Capstone Project\n\nData Scientist, Illuminex AI\nApr 2024 ‚Äì Jun 2024\n‚Ä¢ Developed an object detection pipeline using Faster R-CNN, YOLOv8, and RetinaNet, achieving a 60% mAP for bird strike mitigation at Chengdu Shuangliu Airport, surpassing the previous best of 49.5% AP50.\n‚Ä¢ Pioneered synthetic data augmentation with airplane images, enhancing model realism and boosting predictive accuracy in complex airport environments.\n‚Ä¢ Managed large-scale datasets on AWS, optimizing models for real-time, high-speed processing, and supporting robust validations. Awarded ‚ÄúBest Talk‚Äù in the Master of Data Science program for effectively communicating these complex data insights."
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "ABOUT",
    "section": "Work Experience",
    "text": "Work Experience\n\nData Analyst Intern, Beijing Academy of Social Sciences\nOct 2019 ‚Äì Jan 2020\n‚Ä¢ Optimized MySQL database queries, reducing page load times by 15% and increasing data retrieval speed by 20%, enhancing user experience.\n‚Ä¢ Analyzed over 20,000 records to uncover critical insights, leading to a 12% improvement in student engagement metrics and directly influencing educational program enhancements.\n‚Ä¢ Developed and presented detailed reports and dashboards to senior leadership, highlighting KPIs and trends, which facilitated data-driven decisions and increased operational efficiency by 10%.\n\n\nAudit and Assurance Department Intern, Deloitte\nJul 2019 ‚Äì Aug 2019\n‚Ä¢ Performed financial analysis on major corporations, including Guangshen Railway Co., increasing the accuracy of financial assessments by 20% through data analysis of over 5,000 data points using Python.\n‚Ä¢ Conducted data audits and drafted 15+ financial reports using Power BI, creating clear data visualizations that improved report clarity and reduced review time by 30% for senior stakeholders.\n\n\nInvestment Banking Management Headquarters Intern, Zhongshan Securities\nApr 2019 ‚Äì Jun 2019\n‚Ä¢ Conducted valuation and financial modeling, achieving a 90% accuracy rate in valuation premiums by analyzing growth rates, profitability, and competitive advantages.\n‚Ä¢ Streamlined due diligence processes by 20%, performing in-depth financial analysis and capital structure evaluations, resulting in faster and more informed decision-making.\n\n\nRisk Management Department Intern, Agricultural Bank of China\nJul 2018 ‚Äì Aug 2018\n‚Ä¢ Applied machine learning techniques to analyze over 4,000 loans, improving customer ratings and risk assessments accuracy by 10%.\n‚Ä¢ Collaborated with the risk management team to integrate machine learning insights into financial models, enhancing the accuracy of risk predictions."
  },
  {
    "objectID": "about.html#achievements-and-skills",
    "href": "about.html#achievements-and-skills",
    "title": "ABOUT",
    "section": "Achievements and Skills",
    "text": "Achievements and Skills\n‚Ä¢ Data Visualization: Created visualizations that reduced report review time by 30%.\n‚Ä¢ Efficiency Improvements: Streamlined data analysis processes, reducing preparation time by 25%.\n‚Ä¢ Insight Generation: Specialized in transforming complex datasets into actionable business intelligence."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "PROJECTS",
    "section": "",
    "text": "Still in Progress‚Ä¶.üèó"
  },
  {
    "objectID": "projects.html#airfield-hazards-bird-tracking-at-airports",
    "href": "projects.html#airfield-hazards-bird-tracking-at-airports",
    "title": "PROJECTS",
    "section": "ü¶ÖAirfield Hazards: Bird Tracking at Airports",
    "text": "ü¶ÖAirfield Hazards: Bird Tracking at Airports\n\nDescription: Developed a robust, cost-effective object detection pipeline for real-time bird identification at airports, using models like RetinaNet and YOLOv8, with advanced preprocessing techniques to enhance performance and safety.\nPaper: Original Paper\nTechnologies (Libraries) Used: Python (Altair, Matplotlib, PyTorch, Pandas, NumPy, Pytest), Makefile, AWS\nModels Tried: RetinaNet, YOLOv8, FasterR-CNN\nProject Pipeline\n\n\n\nInteraction between the Scripts"
  },
  {
    "objectID": "projects.html#churn-insights",
    "href": "projects.html#churn-insights",
    "title": "PROJECTS",
    "section": " Churn Insights",
    "text": "Churn Insights\n\nDescription: A project that involved key steps such as performing the ETL process and data cleaning in PostgreSQL, followed by data transformations and creating enhanced visualizations in Tableau. We then built and evaluated various machine learning models, including KNN, Decision Tree, Random Forest, RBF SVM, and Logistic Regression, in Jupyter Notebook. After conducting thorough EDA, we selected the best model to make predictions and present the results.\nTechnologies (Libraries) Used: Python (Altair, Matplotlib, Plotly, PyTorch, Seaborn, Pandas, NumPy), Tableau, PostgreSQL\nGitHub: GitHub Repository"
  },
  {
    "objectID": "projects.html#homescope",
    "href": "projects.html#homescope",
    "title": "PROJECTS",
    "section": " HomeScope",
    "text": "HomeScope\n\nDescription: An analytical platform dedicated to illuminating the real estate market‚Äôs complexities. Aimed at stakeholders such as investors, developers, market analysts, and urban planners, it provides actionable insights through the careful analysis of pivotal variables influencing property values.\nTechnologies (Libraries) Used: Python (Altair, Plotly, Pandas, PyArrow), Dash\nGitHub: GitHub Repository\nLink: Dashboard Website"
  },
  {
    "objectID": "projects.html#cryptopulse",
    "href": "projects.html#cryptopulse",
    "title": "PROJECTS",
    "section": " CryptoPulse",
    "text": "CryptoPulse\n\nDescription: A Shiny dashboard that allows users to interactively explore cryptocurrency data. It provides insights into various cryptocurrencies, with a focus on Bitcoin and Ethereum.\nTechnologies (Libraries) Used: Python (Plotly), R (dplyr), Shiny\nGitHub: GitHub Repository"
  },
  {
    "objectID": "projects.html#pyxplor",
    "href": "projects.html#pyxplor",
    "title": "PROJECTS",
    "section": " Pyxplor",
    "text": "Pyxplor\n\nDescription: A comprehensive Python package designed to automate and streamline the Exploratory Data Analysis (EDA) process. Tailored for various data types including numeric, categorical, binary, and time series data, pyxplor aims to enhance data interpretation through a suite of specialized plotting functions. This package seeks to reduce the complexity and time invested in initial data analysis, making it an essential tool for data scientists and analysts at all levels.\nTechnologies (Libraries) Used: Python (PyPI, Pytest, Seaborn, Pandas), Poetry, Cookiecutter\nGitHub: GitHub Repository\nLink: Docs"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Iris LUO",
    "section": "",
    "text": "HiüëãÔºÅI‚Äôm Iris Luo, a skilled Data Scientist with dual Master‚Äôs degrees in Data Science and Economics, and over two years of experience in data cleaning, data visualization, data modeling, and data analysis."
  }
]